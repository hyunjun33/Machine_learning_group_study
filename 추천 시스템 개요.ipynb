{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# chapter 09 | 추천 시스템\n",
    "\n",
    "## 01. 추천 시스템의 개요와 배경\n",
    "\n",
    "### 추천 시스템의 유형\n",
    "1. 콘텐츠 기반 필터링 방식 (Content based Filtering)\n",
    "2. 협업 필터링 방식 (Collaborative Filtering)  \n",
    "    1) 최근접 이웃 협업 필터링 (Nearest Neighbor)  \n",
    "    ★ 2) 잠재 요인 협업 필터링 (Latent Factor)   \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02. 콘텐츠 기반 필터링 추천 시스템\n",
    "사용자가 특정 아이템을 선호하는 경우, 그 아이템과 비슷한 콘텐츠를 가진 아이템을 추천하는 방식  \n",
    "예) 영화 추천\n",
    "\n",
    "## 03. 최근접 이웃 협업 필터링\n",
    "= 메모리 협업 필터링  \n",
    "- 사용자가 아이템에 매긴 평점 정보나 상품 구매 이력과 같은 사용자 행동 양식(User Behavior) 기반으로 추천하는 방식\n",
    "- 목표 : 사용자-아이템 평점 매트릭스와 같은 축적된 사용자 행동 데이터를 기반으로 사용자가 아직 평가하지 않은 아이템을 예측 평가(Predicted Rating)하는 것\n",
    "\n",
    "#### 사용자-아이템 평점 행렬\n",
    "- 로우 레벨 형태의 데이터를 `pandas.pivot_table()` 함수로 사용자-아이템 평점 행렬로\n",
    "- 일반적으로 많은 아이템을 열로 가지는 다차원 행렬, 희소 행렬(Sparse Matrix)\n",
    "\n",
    "#### 1. 사용자 기반(User-User) 최근접 이웃\n",
    "> 당신과 비슷한 고객들이 다음 상품도 구매\n",
    "\n",
    "- 특정 사용자와 유사한 다른 사용자를 TOP-N으로 선정해 이 TOP-N 사용자가 좋아하는 아이템을 추천하는 방식  \n",
    "- 특정 사용자와 타 사용자 간의 유사도를 측정한 뒤 가장 유사도가 높은 TOP-N 사용자를 추출해 그들이 선호하는 아이템을 추천  \n",
    "(예) 사용자 A에게는 사용자 C보다는 유사도가 비슷한 사용자 B가 추천한 영화를 추천하는 것이 좋다.\n",
    "\n",
    "|USER | 다크나이트| 인터스텔라| 엣지오브투모로우|프로메테우스|스타워즈|\n",
    "|:-:|:-:|:-:|:-:|:-:|:-:|\n",
    "|A|5|4|4| | |\n",
    "|B|5|3|4|5|3|\n",
    "|C|4|3|3|2|5|\n",
    "\n",
    "#### 2. 아이템 기반(Item-Item) 최근접 이웃\n",
    "> 이 상품을 선택한 다른 고객들은 다음 상품도 구매\n",
    "\n",
    "- '아이템 간의 속성'이 얼마나 비슷한지 X, 사용자들이 그 아이템을 좋아하는지/싫어하는지의 평가 척도가 유사한 아이템을 추천하는 알고리즘  \n",
    "(예) 아이템 다크나이트와 스타워즈의 평점 분포가 비슷하므로 서로 유사도가 높다. 따라서 다크나이트를 좋아하는 사용자 D에게 스타워즈를 추천해준다.\n",
    "\n",
    "|USER | A | B | C | D | E |\n",
    "|:-:|:-:|:-:|:-:|:-:|:-:|\n",
    "|다크나이트|5|4|5|5|5|\n",
    "|프로메테우스|5|4|4| |5|\n",
    "|스타워즈|4|3|3| |4|\n",
    "\n",
    "#### 알고리즘 선택\n",
    "- 일반적으로 사용자 기반보다는 아이템 기반 협업 필터링이 정확도가 더 높다. 비슷한 아이템을 좋아한다고 해서 사람들의 취향이 비슷하다고 판단하기는 어렵기 때문에. \n",
    "- 매우 유명한 영화는 취향과 관계없이 대부분의 사람이 관람하는 경우가 많고, 사용자들이 평점을 매긴 영화가 많지 않은 경우가 일반적인데 이를 기반으로 다른 사람과의 유사도를 비교하기 어려운 점이 있다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 04. 잠재 요인 협업 필터링\n",
    "\n",
    "\n",
    "### 잠재 요인 협업 필터링의 이해\n",
    "\n",
    "- 사용자-아이템 평점 행렬 속에 숨어있는 잠재 요인을 추출해 추천 예측을 할 수 있게 하는 기법  \n",
    "- 행렬 분해 (Matrix Factorization) : 대규모 다차원 행렬을 SVD와 같은 차원 축소 기법으로 분해하는 과정에서 잠재 요인을 추출하는 기법\n",
    "\n",
    "#### 작동 방식\n",
    "1. 잠재 요인을 기반으로 다차원 희소 행렬인 사용자-아이템 행렬 데이터를 저차원 밀집 행렬의 사용자-잠재요인 행렬의 전치 행렬로 분해\n",
    "2. 분해된 두 행렬의 내적을 통해 새로운 사용자-아이템 행렬 데이터를 만들어 사용자가 아직 평점을 부여하지 않은 아이템에 대한 예측 평점을 생성\n",
    "\n",
    "<img src='https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcdvvI5%2FbtqJjvqsdaR%2FSAphevCut5XmWOppViZk1K%2Fimg.png'>\n",
    "\n",
    "### 행렬 분해의 이해\n",
    "1. SVD(Singular Vector Decomposition)\n",
    "2. NMF(Non-Negative Matrix Factorization)\n",
    "\n",
    "- M개의 사용자(User) 행과 N개의 아이템(Item) 열을 가진 평점 행렬 $R$ : $M \\times N$ 차원으로 구성\n",
    "- 행렬 분해를 통해 사용자-K 차원 잠재 요인 행렬 $P$ : $M \\times K$ 차원으로 구성 *(그림에서는 $\\hat{U}$)*\n",
    "- 아이템-잠재 요인 행렬 $Q$ : $N \\times K$ 차원으로 구성 *(그림에서는 $\\hat{V}$)*\n",
    "\n",
    "\n",
    "<img src='https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbzEtMB%2FbtqCzCb87aV%2FuoEv3HmgydjtQSNLNXZTt1%2Fimg.png'>\n",
    "\n",
    "- $R$ 행렬의 u행 사용자의 i열 아이템에 대한 평점 데이터 $r_{u,i} \\approx \\hat{r}_{u,i} = p_{u} \\times q_{i}^{t}$  \n",
    "cf. 행렬 $R$을 분해한 $P$와 $Q$ 행렬을 내적한 예측 행렬을 $\\hat{R}$ 행렬이라고 하자"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 확률적 경사 하강법(Stochastic Gradient Descent, SGD)을 이용한 행렬 분해\n",
    "cf. SVD는 NaN값이 있는 행렬에는 적용할 수 없기 때문에 아직 평점이 입력되지 않은 요소가 많은 $R$ 행렬에는 SVD 방식을 사용할 수 없다.\n",
    "\n",
    "#### 목표\n",
    "P와 Q 행렬로 계산된 예측 R 행렬 값이 실제 R 행렬 값과 가장 최소의 오류를 가질 수 있도록 반복적인 비용 함수 최적화를 통해 P와 Q를 유추\n",
    "$$ R = \\hat{R} + min(error(P,Q)) $$\n",
    "\n",
    "#### 과정\n",
    "1. 임의의 $P$와 $Q$ 설정\n",
    "2. $P$와 $Q.T$을 곱해 예측 $\\hat{R}$을 계산하고 오류 값 계산\n",
    "3. 이 오류 값을 최소화할 수 있도록 $P$와 $Q$ 행렬을 적절한 값으로 업데이터\n",
    "4. 만족할만한 오류 값을 가질 때까지 2~3 과정을 반복\n",
    "\n",
    "#### 비용 함수 = 오류 최소화 + L2 규제\n",
    "$$ min \\sum(r_{(u,i)} - p_{u} q_{i}^{t})^{2} + \\lambda ( \\parallel q_{i} \\parallel^{2} + \\parallel p_{u} \\parallel ^{2} )$$\n",
    "\n",
    "#### 업데이트 p, q\n",
    "$$\\acute{p_{u}} = p_{u} + \\eta * (e_{(u,i)} *q_{i} - \\lambda * p_{u})$$\n",
    "$$\\acute{q_{i}} = q_{i} + \\eta * (e_{(u,i)} *p_{u} - \\lambda * q_{i}) $$\n",
    "- $p_{u}$ : P 행렬의 사용자 u행 벡터\n",
    "- $q_{i}^{t}$ : Q 행렬의 아이템 i행의 전치 벡터(transpose vector)\n",
    "- $r_{(u,i)}$ : 실제 R 행렬의 u행, i열에 위치한 값\n",
    "- $\\hat{r}_{(u,i)}$ : 예측 $\\hat{R}$ 행렬의 u행, i열에 위치한 값, $p_{u} *q_{i}^{t}$로 계산\n",
    "- $e_{(u,i)}$ : u행, i열에 위치한 실제 행렬 값과 예측 행렬 값 차이(오류), $r_{(u,i)} - \\hat{r}_{(u,i)}$로 계산\n",
    "- $\\eta$ : 학습률 (learning rate)\n",
    "- $\\lambda $ : L2 규제 계수 (alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = np.array([[4, np.NaN, np.NaN, 2, np.NaN ],\n",
    "              [np.NaN, 5, np.NaN, 3, 1 ],\n",
    "              [np.NaN, np.NaN, 3, 4, 4 ],\n",
    "              [5, 2, 1, 2, np.NaN ]])\n",
    "\n",
    "n_users, n_items = R.shape\n",
    "K = 3 # n_latent_factor\n",
    "\n",
    "P = np.random.normal(scale = 1./K, size=(n_user, K))\n",
    "Q = np.random.normal(scale = 1./K, size=(n_item, K))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### get_rmse()\n",
    "실제 $R$행렬과 예측 $\\hat{R}$ 행렬의 오차를 구하는 함수\n",
    "- `non_zeros` : 행렬 R의 요소 중에 0 이상인 요소에 대해 (x_idx, y_idx, value)을 묶은 리스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def get_rmse(R, P, Q, non_zeros):\n",
    "#     err = 0\n",
    "    R_pred = np.dot(P, Q.T)\n",
    "    \n",
    "    x_non_zeros = [non_zero[0] for non_zero in non_zeros]\n",
    "    y_non_zeros = [non_zero[1] for non_zero in non_zeros]\n",
    "    R_non_zeros = R[x_non_zeros, y_non_zeros]\n",
    "    R_pred_non_zeros = R_pred[x_non_zeros, y_non_zeros]\n",
    "\n",
    "    mse = mean_squared_error(R_non_zeros, R_pred_non_zeros)\n",
    "    rmse = np.sqrt(mse)\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.3221319166843153"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_zeros = [ (i,j,R[i,j]) for i in range(n_users) for j in range(n_items) if R[i,j]>0 ]\n",
    "    \n",
    "get_rmse(R, P, Q, non_zeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 \t 0.02628856238864382\n",
      "50 \t 0.02602647104969237\n",
      "100 \t 0.025785709856092767\n",
      "150 \t 0.025562448833898\n",
      "200 \t 0.02535356509998432\n",
      "250 \t 0.025156521754677308\n",
      "300 \t 0.02496926503647837\n",
      "350 \t 0.024790137781376453\n",
      "400 \t 0.024617807121820514\n",
      "450 \t 0.02445120442989814\n",
      "500 \t 0.024289475669516225\n",
      "550 \t 0.024131940521167395\n",
      "600 \t 0.023978058850170722\n",
      "650 \t 0.023827403288374824\n",
      "700 \t 0.023679636881945427\n",
      "750 \t 0.02353449492065436\n",
      "800 \t 0.02339177020637548\n",
      "850 \t 0.023251301141192143\n",
      "900 \t 0.02311296212026737\n",
      "950 \t 0.02297665580339435\n"
     ]
    }
   ],
   "source": [
    "steps = 1000\n",
    "learning_rate = 0.01\n",
    "r_lambda = 0.01\n",
    "\n",
    "for step in range(steps):\n",
    "    for i, j, r in non_zeros :\n",
    "        eij = R[i,j] - np.dot(P[i,:], Q[j,:].T)\n",
    "        \n",
    "        P[i,:] = P[i, :] + learning_rate * (eij * Q[j,:] - r_lambda * P[i, :])\n",
    "        Q[j,:] = Q[j, :] + learning_rate * (eij * P[i,:] - r_lambda * Q[j, :])\n",
    "        \n",
    "    rmse = get_rmse(R, P, Q, non_zeros)\n",
    "    if (step%50 == 0):\n",
    "        print(step,'\\t', rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.996  1.6    0.795  1.993  1.55 ]\n",
      " [ 6.847  4.976 -0.027  2.981  1.004]\n",
      " [ 9.029  1.892  2.98   3.973  3.988]\n",
      " [ 4.956  2.013  1.025  2.035  1.509]]\n"
     ]
    }
   ],
   "source": [
    "pred_mat = np.dot(P, Q.T)\n",
    "print(np.round(pred_mat,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 이미지\n",
    "- [추천 시스템 - Surprise를 이용한 잠재 요인 협업 필터링 추천] Book-Crossing: 사용자 리뷰 평점 데이터 세트 [링크](https://hipster4020.tistory.com/115)\n",
    "- [CF] MF(Matrix Factorization, 행렬분해) [링크](https://ekdud7667.tistory.com/entry/CF-MFMatrix-Factorization-%ED%96%89%EB%A0%AC%EB%B6%84%ED%95%B4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
